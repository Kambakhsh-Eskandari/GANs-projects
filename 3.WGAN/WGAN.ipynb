{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grad_hook():\n",
    "    '''\n",
    "    Function to keep track of gradients for visualization purposes, \n",
    "    which fills the grads list when using model.apply(grad_hook).\n",
    "    '''\n",
    "    grads = []\n",
    "    def grad_hook(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            grads.append(m.weight.grad)\n",
    "    return grads, grad_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise generation\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    \n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "   \n",
    "    def __init__(self, z_dim=64, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "     \n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor,\n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic (in W-GANS we discriminators are called critics because they give you scores)\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, im_chan=1, hidden_dim = 64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            self.make_critic_block(im_chan, hidden_dim),\n",
    "            self.make_critic_block(hidden_dim, hidden_dim*2),\n",
    "            self.make_critic_block(hidden_dim*2, 1, final_layer=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def make_critic_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "            \n",
    "    def forward(self, image):\n",
    "        # returns a 1D tensor of image\n",
    "        critic_pred = self.critic(image)\n",
    "        return critic_pred.view(len(critic_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training initialization\n",
    "n_epochs = 100\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "c_lambda = 10\n",
    "crit_repeats = 5\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=False, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializing generator, critic, and optimizers.\n",
    "gen = Generator().to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr = lr, betas=(beta_1, beta_2))\n",
    "\n",
    "crit = Critic().to(device)\n",
    "crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit, real, fake, epsilon):\n",
    "    ## mix images\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\n",
    "    \n",
    "    ## critic's score\n",
    "    mixed_scores = crit(mixed_images)\n",
    "    \n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(inputs=mixed_images, outputs=mixed_scores,\n",
    "                                   grad_outputs=torch.ones_like(mixed_scores),\n",
    "                                   create_graph=True, retain_graph=True)[0]\n",
    "    return gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    ## flatten gradients so each row captures one image\n",
    "    gradient = gradient.veiw(len(gradient), -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    penalty = torch.mean((gradient_norm - 1)**2)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## losses\n",
    "def get_gen_loss(critic_fake_pred):\n",
    "    gen_loss = -torch.mean(critic_fake_pred)\n",
    "\n",
    "def get_critic_loss(critic_fake_pred, critic_real_pred, gp, c_lambda):\n",
    "    critic_loss = torch.mean(critic_fake_pred) - torch.mean(critic_real_pred) + c_lambda*gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a300915ad20456f92480f35c6747dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m real,_ \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     cur_batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(real)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     real \u001b[39m=\u001b[39m real\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     mean_iteration_critic_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(crit_repeats):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kambakhsh/git_workspace/GANs-projects/3.WGAN/WGAN.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39m## critic \u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "## actual training\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "\n",
    "for epcoh in range(n_epochs):\n",
    "    # load data\n",
    "    for real,_ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        \n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "        \n",
    "            ## critic \n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake= gen(fake_noise)\n",
    "            crit_fake_pred = crit(fake.detach())\n",
    "            crit_real_pred = crit(real)\n",
    "            \n",
    "            epsilon = torch.rand(len(real),1,1,1, device=device, requires_grad=True)\n",
    "            gradient = get_gradient(crit, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_critic_loss(crit_fake_pred, crit_real_pred, gp, c_lambda)\n",
    "            \n",
    "            # Keep track of the average critic loss in this batch\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "            \n",
    "            #update gradients \n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            #update optimizer\n",
    "            crit_opt.step()\n",
    "        \n",
    "    critic_losses += [mean_iteration_critic_loss]\n",
    "    \n",
    "    ## generator\n",
    "    gen_opt.zero_grad()\n",
    "    fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "    fake_2 = gen(fake_noise_2)\n",
    "    crit_fake_pred = crit(fake_2)\n",
    "    gen_loss = get_gen_loss(crit_fake_pred)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "    \n",
    "    # Keep track of the average generator loss in this batch\n",
    "    generator_losses += [gen_loss.item()]\n",
    "    \n",
    "    ## visualization\n",
    "    if cur_step % display_step == 0 and cur_step > 0:\n",
    "        gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "        crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "        print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "        show_tensor_images(fake)\n",
    "        show_tensor_images(real)\n",
    "        step_bins = 20\n",
    "        num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "        plt.plot(range(num_examples // step_bins),\n",
    "                 torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                 label=\"Generator Loss\")\n",
    "        plt.plot(range(num_examples // step_bins),\n",
    "                 torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                 label=\"Critic Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    cur_step +=1\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4203a32042407df730931a86b742f575d69064a0f187fd97fd1688a224d0821b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
